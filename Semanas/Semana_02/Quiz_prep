# Revis√£o Consolidada: Semana 02

Este documento sintetiza os principais pontos t√©cnicos abordados nos quizzes, focando em Pr√©-processamento, Arquiteturas e Modelos Lineares.

---

## 1. Pr√©-processamento e Qualidade dos Dados

O pr√©-processamento √© uma etapa cr√≠tica que prepara os dados brutos para serem "compreendidos" pela rede neural.

### Rotinas de Pr√©-processamento:

* **Normaliza√ß√£o:** Equilibrar a escala dos atributos.
* **Transforma√ß√£o Categ√≥rica para Num√©rica:** Redes neurais operam exclusivamente com n√∫meros; atributos simb√≥licos (ex: "Sim/N√£o", "Cores") devem ser convertidos (ex: One-Hot Encoding).
* **Imputa√ß√£o de Atributos Faltantes:** Lidar com buracos na base de dados (excluindo registros ou preenchendo-os com m√©dias/medianas).
* **Sele√ß√£o de Atributos:** Identificar quais vari√°veis s√£o realmente relevantes para o problema.

### Tratamento de Classe Minorit√°ria (Desbalanceamento):

Em problemas onde uma classe ocorre raramente (ex: falhas em sensores industriais), a acur√°cia geral pode ser alta enquanto o desempenho na classe importante √© p√≠fio.

* **Solu√ß√£o:** Ajustar a distribui√ß√£o de classes atrav√©s de **t√©cnicas de reamostragem** (oversampling ou undersampling).

---

## 2. Arquiteturas e Deep Learning

A forma como os neur√¥nios se organizam dita a capacidade de abstra√ß√£o do modelo.

### Redes Convolucionais (CNNs):

* **Caracter√≠stica:** Utilizam **filtros locais** para extrair padr√µes em regi√µes espec√≠ficas do sinal (como bordas em imagens) e replicam esses padr√µes atrav√©s do compartilhamento de pesos.

### O Ecossistema do Aprendizado Profundo:

1. **Estrutura:** Composta por **m√∫ltiplas camadas**.
2. **Aprendizado:** Ocorre de forma **progressiva**, extraindo caracter√≠sticas simples nas primeiras camadas e complexas nas √∫ltimas.
3. **Aplica√ß√£o:** Ap√≥s treinada, a rede realiza a **infer√™ncia** em novos exemplos.

---

## 3. Modelos Lineares: Perceptron vs. Adaline

Ambos s√£o a base do aprendizado supervisionado, mas diferem no c√°lculo do erro e na otimiza√ß√£o.

### O Perceptron

* Composto por neur√¥nios do tipo MCP com uma camada de processadores ajust√°veis.
* **Converg√™ncia:** Se o problema for **linearmente separ√°vel**, ele sempre encontrar√° o hiperplano de separa√ß√£o.
* **Capacidade:** Simula portas l√≥gicas lineares (**AND, OR, NOT**).

### O Adaline (*Adaptive Linear Neuron*)

A grande evolu√ß√£o do Adaline √© a introdu√ß√£o do **Gradiente Descendente** para otimiza√ß√£o.

| Caracter√≠stica | Detalhe T√©cnico |
| --- | --- |
| **C√°lculo do Erro** | Ocorre **antes da fun√ß√£o de ativa√ß√£o** (baseado na sa√≠da linear). |
| **Objetivo** | Minimizar a **soma dos erros quadr√°ticos** (MSE). |
| **Aprendizado** | Utiliza a derivada da fun√ß√£o de custo para ajustar os pesos. |

---

## üí° Destaques para Revis√£o de Prova

* **Aten√ß√£o ao Erro:** Se a quest√£o mencionar erro "antes da ativa√ß√£o", a resposta √© Adaline. Se for "corre√ß√£o de erro ap√≥s a sa√≠da discreta", √© Perceptron.
* **Aten√ß√£o ao Processamento:** "Sele√ß√£o de exemplos representativos" **n√£o** √© pr√©-processamento, √© uma tarefa final do aprendizado.
* **Aten√ß√£o √† Converg√™ncia:** O Perceptron falha em problemas n√£o-lineares (como a porta XOR), mas √© infal√≠vel em problemas lineares.

---

Para validar a **Quest√£o 5** (Desbalanceamento), simulando o impacto de um conjunto de dados desbalanceado no seu terminal:

```python
import numpy as np

# Simula√ß√£o de dados: 990 normais (0) e 10 falhas (1)
y_real = np.array([0]*990 + [1]*10)
# Um modelo "pregui√ßoso" que sempre chuta 0 (normal)
y_pred = np.zeros(1000)

acuracia = (y_real == y_pred).sum() / len(y_real)
print(f"Acur√°cia Geral: {acuracia*100}%") 
# Resultado: 99%, mas ele errou TODAS as falhas cr√≠ticas.

```