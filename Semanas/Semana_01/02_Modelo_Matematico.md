# üß¨ Semana 01: O Neur√¥nio Biol√≥gico e sua Modelagem Matem√°tica

Esta se√ß√£o detalha como traduzimos impulsos eletroqu√≠micos em opera√ß√µes de √°lgebra linear.

## 1. O Modelo do Neur√¥nio (Haykin 1.2)

Um neur√¥nio artificial √© composto por tr√™s elementos b√°sicos e um ajuste externo (Bias).

### Os Tr√™s Elementos B√°sicos

1. **Conjunto de Sinapses (Pesos):** Cada sinal de entrada  √© multiplicado por um peso .
* *Nota:* Um peso positivo √© **excitat√≥rio**, um negativo √© **inibit√≥rio**.


2. **Jun√ß√£o Somadora:** Um somador linear que agrega os sinais de entrada ponderados.
3. **Fun√ß√£o de Ativa√ß√£o ($\phi$):** Limita a amplitude da sa√≠da do neur√¥nio. Tamb√©m chamada de fun√ß√£o de esmagamento (*squashing function*).

### O Papel do Bias ($b_k$)

O bias tem o efeito de aumentar ou diminuir a entrada l√≠quida da fun√ß√£o de ativa√ß√£o, dependendo se √© positivo ou negativo.

* **Matematicamente:** Ele "desloca" a fun√ß√£o de ativa√ß√£o para a esquerda ou para a direita no eixo .
* **Equa√ß√£o do Potencial de Ativa√ß√£o ($v_k$):**

$$v_k = \sum_{j=1}^{m} w_{kj} x_j + b_k$$

---

## 2. Fun√ß√µes de Ativa√ß√£o Comuns

A escolha da fun√ß√£o determina como o neur√¥nio "responde" aos est√≠mulos. As principais citadas por Haykin s√£o:

| Fun√ß√£o | Equa√ß√£o | Comportamento |
| --- | --- | --- |
| **Degrau (Threshold)** | $\phi(v) = 1 \text{ se } v \geq 0; \text{ sen√£o } 0$ | Sa√≠da bin√°ria (0 ou 1). Modelo original de McCulloch-Pitts. |
| **Sigmoide (Log√≠stica)** | $\phi(v) = \frac{1}{1 + \exp(-v)}$ | Sa√≠da entre 0 e 1. √ötil para probabilidades. |
| **Tangente Hiperb√≥lica** | $\phi(v) = \tanh(v)$ | Sa√≠da entre -1 e 1. Frequentemente preferida √† sigmoide em redes profundas. |

---

## 3. Redes Neurais como Grafos Direcionados (Haykin 1.3)

Haykin introduz a vis√£o da rede como um **Grafo de Fluxo de Sinais**. Isso √© fundamental para entender como os dados se propagam:

* **N√≥s:** Representam os neur√¥nios ou pontos de entrada.
* **Arcos (Arestas):** Representam as conex√µes sin√°pticas.
* **Fluxo:** O sinal sempre flui em uma dire√ß√£o (da entrada para a sa√≠da) em redes *feedforward*.

> **Conceito de Engenharia:** Um neur√¥nio pode ser visto como um operador matem√°tico que transforma um vetor de entrada  em um escalar de sa√≠da .

---

## üìù Checkpoint para o Quiz

* **Diferen√ßa entre $u_k$ e $v_k$:** No livro de Haykin,  √© a soma linear ($\sum w x$), enquanto $v_k$ √© o potencial de ativa√ß√£o j√° somado ao bias ($u_k + b_k$).
* **Linearidade:** O somador √© uma opera√ß√£o **linear**. O que traz a capacidade de aprender padr√µes complexos para a rede √© a **n√£o-linearidade** da fun√ß√£o de ativa√ß√£o.
* **Sinapses Inibit√≥rias:** Identificadas por pesos negativos ($w < 0$).